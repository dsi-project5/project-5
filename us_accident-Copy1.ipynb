{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set(style = 'darkgrid')\n",
    "\n",
    "import geopandas as gpd\n",
    "from keplergl import KeplerGl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "**Reading in Accident Data**\n",
    "__________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Source</th>\n",
       "      <th>TMC</th>\n",
       "      <th>Severity</th>\n",
       "      <th>Start_Time</th>\n",
       "      <th>End_Time</th>\n",
       "      <th>Start_Lat</th>\n",
       "      <th>Start_Lng</th>\n",
       "      <th>End_Lat</th>\n",
       "      <th>End_Lng</th>\n",
       "      <th>...</th>\n",
       "      <th>Roundabout</th>\n",
       "      <th>Station</th>\n",
       "      <th>Stop</th>\n",
       "      <th>Traffic_Calming</th>\n",
       "      <th>Traffic_Signal</th>\n",
       "      <th>Turning_Loop</th>\n",
       "      <th>Sunrise_Sunset</th>\n",
       "      <th>Civil_Twilight</th>\n",
       "      <th>Nautical_Twilight</th>\n",
       "      <th>Astronomical_Twilight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1</td>\n",
       "      <td>MapQuest</td>\n",
       "      <td>201.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2016-02-08 05:46:00</td>\n",
       "      <td>2016-02-08 11:00:00</td>\n",
       "      <td>39.865147</td>\n",
       "      <td>-84.058723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "      <td>Night</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID    Source    TMC  Severity           Start_Time             End_Time  \\\n",
       "0  A-1  MapQuest  201.0         3  2016-02-08 05:46:00  2016-02-08 11:00:00   \n",
       "\n",
       "   Start_Lat  Start_Lng  End_Lat  End_Lng  ...  Roundabout Station   Stop  \\\n",
       "0  39.865147 -84.058723      NaN      NaN  ...       False   False  False   \n",
       "\n",
       "  Traffic_Calming Traffic_Signal Turning_Loop Sunrise_Sunset Civil_Twilight  \\\n",
       "0           False          False        False          Night          Night   \n",
       "\n",
       "  Nautical_Twilight Astronomical_Twilight  \n",
       "0             Night                 Night  \n",
       "\n",
       "[1 rows x 49 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in Dataframe with All the accident data\n",
    "acc_df = pd.read_csv('../data/US_Accidents_Dec20.csv')\n",
    "acc_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower and eliminate spaces in column names\n",
    "acc_df.columns = acc_df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unneccessary columns or columns with lots of nulls\n",
    "acc_df.drop(columns = ['id','source','end_lat','end_lng',\n",
    "                       'description','number','street',\n",
    "                       'country','timezone','weather_timestamp', \n",
    "                       'airport_code', 'zipcode', 'tmc'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "**Reading in Population Density Data**\n",
    "_______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pop_dense_cnty = pd.read_csv('../data/pop_density_county.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower and eliminate spaces in column names\n",
    "pop_dense_cnty.columns = pop_dense_cnty.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>county_name</th>\n",
       "      <th>density_mi</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New York</td>\n",
       "      <td>69,468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     county_name density_mi\n",
       "Rank                       \n",
       "1       New York     69,468"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pop_dense_cnty.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "**Read in License Data**, Format into DF, Prepare for Concatenation\n",
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in Dataframe with data on driver's licensing in each state\n",
    "license_df = pd.read_csv('../data/licensed_drivers_by_state.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>UNDER</th>\n",
       "      <th>20-24</th>\n",
       "      <th>25-29</th>\n",
       "      <th>30-34</th>\n",
       "      <th>35-39</th>\n",
       "      <th>40-44</th>\n",
       "      <th>45-49</th>\n",
       "      <th>50-54</th>\n",
       "      <th>55-59</th>\n",
       "      <th>60-64</th>\n",
       "      <th>65-69</th>\n",
       "      <th>70-74</th>\n",
       "      <th>75-79</th>\n",
       "      <th>80-84</th>\n",
       "      <th>OVER</th>\n",
       "      <th>total_drivers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Alabama</td>\n",
       "      <td>219,648</td>\n",
       "      <td>327,163</td>\n",
       "      <td>347,679</td>\n",
       "      <td>320,583</td>\n",
       "      <td>307,331</td>\n",
       "      <td>292,967</td>\n",
       "      <td>311,675</td>\n",
       "      <td>309,970</td>\n",
       "      <td>339,239</td>\n",
       "      <td>327,915</td>\n",
       "      <td>286,986</td>\n",
       "      <td>242,004</td>\n",
       "      <td>168,934</td>\n",
       "      <td>113,483</td>\n",
       "      <td>110,574</td>\n",
       "      <td>4,026,151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     STATE    UNDER    20-24    25-29    30-34    35-39    40-44    45-49  \\\n",
       "0  Alabama  219,648  327,163  347,679  320,583  307,331  292,967  311,675   \n",
       "\n",
       "     50-54    55-59    60-64    65-69    70-74    75-79    80-84     OVER  \\\n",
       "0  309,970  339,239  327,915  286,986  242,004  168,934  113,483  110,574   \n",
       "\n",
       "  total_drivers  \n",
       "0     4,026,151  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower and eliminate spaces in column names for license_df\n",
    "license_df.columns = license_df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminating commas from total drivers column\n",
    "license_df['total_drivers'] = license_df['total_drivers'].str.replace(',', '')\n",
    "# converting total_drivers column to integer type\n",
    "license_df['total_drivers'] = license_df['total_drivers'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating df with only state column and total drivers columns\n",
    "license_df = license_df.loc[:, ['state', 'total_drivers']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "license_df['state'] = license_df['state'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replacing dist of col. with district of columbia so I can concatenate with other dfs\n",
    "license_df['state'].replace('dist. of col. ', 'district of columbia', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the state to index and dropping alaska and hawaii since they're not in accident data\n",
    "license_df.set_index('state', inplace = True)\n",
    "license_df.drop(['alaska', 'hawaii'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "license_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting index alphabetically and ensuring proper format\n",
    "license_df.sort_index(inplace = True)\n",
    "license_df.index = license_df.index.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "**Read in Shape Files**, Format into DF and Prepare for Concatenation\n",
    "______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_shape = gpd.read_file('../data/cb_2018_us_state_500k/cb_2018_us_state_500k.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping island territories\n",
    "national_shape.drop([13, 27, 37, 38, 42, 44, 45], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower and eliminate spaces in column names\n",
    "national_shape.columns = national_shape.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting state name column to lowercase\n",
    "national_shape['name'] = national_shape['name'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_shape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting index to name of state to prepare for concatenation\n",
    "national_shape.set_index(keys = 'name', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sorting index alphabetically and ensuring proper format\n",
    "national_shape.sort_index(inplace = True)\n",
    "national_shape.index = national_shape.index.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "________\n",
    "**Create State Accident Counts**, Form into DF and Prepare for Concatenation\n",
    "________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>severity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>state</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AL</th>\n",
       "      <td>56989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AR</th>\n",
       "      <td>5089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AZ</th>\n",
       "      <td>93038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CA</th>\n",
       "      <td>971856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>54028</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       severity\n",
       "state          \n",
       "AL        56989\n",
       "AR         5089\n",
       "AZ        93038\n",
       "CA       971856\n",
       "CO        54028"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Grouping acc_df by state and getting count of all accidents by state\n",
    "# using severity column to get counts but I will change it to a column called counts later. \n",
    "state_count = acc_df.groupby('state').count()[['severity']]\n",
    "state_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index to numeric so I can map full state names to abbreviated names\n",
    "state_count = state_count.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=49, step=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_count.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_remap = {'AL': 'alabama', 'AR': 'arkansas', 'AZ': 'arizona', 'CA': 'california', 'CO': 'colorado',\n",
    " 'CT': 'connecticut', 'DC': 'district of columbia', 'DE': 'delaware', 'FL': 'florida',\n",
    " 'GA': 'georgia', 'IA': 'iowa', 'ID': 'idaho', 'IL': 'illinois',\n",
    " 'IN': 'indiana', 'KS': 'kansas', 'KY': 'kentucky', 'LA': 'louisiana',\n",
    " 'MA': 'massachusetts', 'MD': 'maryland', 'ME': 'maine', 'MI': 'michigan',\n",
    " 'MN': 'minnesota', 'MO': 'missouri', 'MS': 'mississippi', 'MT': 'montana',\n",
    " 'NC': 'north carolina', 'ND': 'north dakota', 'NE': 'nebraska',\n",
    " 'NH': 'new hampshire', 'NJ': 'new jersey', 'NM': 'new mexico', 'NV': 'nevada',\n",
    " 'NY': 'new york', 'OH': 'ohio', 'OK': 'oklahoma', 'OR': 'oregon',\n",
    " 'PA': 'pennsylvania', 'RI': 'rhode island', 'SC': 'south carolina',\n",
    " 'SD': 'south dakota', 'TN': 'tennessee', 'TX': 'texas', 'UT': 'utah',\n",
    " 'VA': 'virginia', 'VT': 'vermont', 'WA': 'washington',\n",
    " 'WI': 'wisconsin', 'WV': 'west virginia', 'WY':  'wyoming'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mapping full names to abbreviated state names\n",
    "state_count['state'] = state_count['state'].map(state_remap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming id column to count.\n",
    "state_count.rename(columns = {'severity': 'count', }, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>alabama</td>\n",
       "      <td>56989</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     state  count\n",
       "0  alabama  56989"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_count.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index to state so that it can be concatenated with license data\n",
    "state_count.set_index(keys = 'state', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorting index alphabetically and ensuring proper format\n",
    "state_count.sort_index(inplace = True)\n",
    "state_count.index = state_count.index.str.lower().str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_count.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "**Concatenating Grouped DF's**\n",
    "_______"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(49, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combining state_count, national_shape and license_df into one df. \n",
    "national_group = pd.concat([state_count, national_shape, license_df], axis = 1, verify_integrity = True)\n",
    "national_group.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['count', 'statefp', 'statens', 'affgeoid', 'geoid', 'stusps', 'lsad',\n",
       "       'aland', 'awater', 'geometry', 'total_drivers'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_group.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>statefp</th>\n",
       "      <th>statens</th>\n",
       "      <th>affgeoid</th>\n",
       "      <th>geoid</th>\n",
       "      <th>stusps</th>\n",
       "      <th>lsad</th>\n",
       "      <th>aland</th>\n",
       "      <th>awater</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_drivers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alabama</th>\n",
       "      <td>56989</td>\n",
       "      <td>01</td>\n",
       "      <td>01779775</td>\n",
       "      <td>0400000US01</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>00</td>\n",
       "      <td>131174048583</td>\n",
       "      <td>4593327154</td>\n",
       "      <td>MULTIPOLYGON (((-88.05338 30.50699, -88.05109 ...</td>\n",
       "      <td>4026151</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         count statefp   statens     affgeoid geoid stusps lsad         aland  \\\n",
       "alabama  56989      01  01779775  0400000US01    01     AL   00  131174048583   \n",
       "\n",
       "             awater                                           geometry  \\\n",
       "alabama  4593327154  MULTIPOLYGON (((-88.05338 30.50699, -88.05109 ...   \n",
       "\n",
       "         total_drivers  \n",
       "alabama        4026151  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_group.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_group['acc_per_cap'] = national_group['count'] / national_group['total_drivers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>statefp</th>\n",
       "      <th>statens</th>\n",
       "      <th>affgeoid</th>\n",
       "      <th>geoid</th>\n",
       "      <th>stusps</th>\n",
       "      <th>lsad</th>\n",
       "      <th>aland</th>\n",
       "      <th>awater</th>\n",
       "      <th>geometry</th>\n",
       "      <th>total_drivers</th>\n",
       "      <th>acc_per_cap</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>alabama</th>\n",
       "      <td>56989</td>\n",
       "      <td>01</td>\n",
       "      <td>01779775</td>\n",
       "      <td>0400000US01</td>\n",
       "      <td>01</td>\n",
       "      <td>AL</td>\n",
       "      <td>00</td>\n",
       "      <td>131174048583</td>\n",
       "      <td>4593327154</td>\n",
       "      <td>MULTIPOLYGON (((-88.05338 30.50699, -88.05109 ...</td>\n",
       "      <td>4026151</td>\n",
       "      <td>0.014155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arizona</th>\n",
       "      <td>93038</td>\n",
       "      <td>04</td>\n",
       "      <td>01779777</td>\n",
       "      <td>0400000US04</td>\n",
       "      <td>04</td>\n",
       "      <td>AZ</td>\n",
       "      <td>00</td>\n",
       "      <td>294198551143</td>\n",
       "      <td>1027337603</td>\n",
       "      <td>POLYGON ((-114.81629 32.50804, -114.81432 32.5...</td>\n",
       "      <td>5369210</td>\n",
       "      <td>0.017328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>arkansas</th>\n",
       "      <td>5089</td>\n",
       "      <td>05</td>\n",
       "      <td>00068085</td>\n",
       "      <td>0400000US05</td>\n",
       "      <td>05</td>\n",
       "      <td>AR</td>\n",
       "      <td>00</td>\n",
       "      <td>134768872727</td>\n",
       "      <td>2962859592</td>\n",
       "      <td>POLYGON ((-94.61783 36.49941, -94.61765 36.499...</td>\n",
       "      <td>2153929</td>\n",
       "      <td>0.002363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>california</th>\n",
       "      <td>971856</td>\n",
       "      <td>06</td>\n",
       "      <td>01779778</td>\n",
       "      <td>0400000US06</td>\n",
       "      <td>06</td>\n",
       "      <td>CA</td>\n",
       "      <td>00</td>\n",
       "      <td>403503931312</td>\n",
       "      <td>20463871877</td>\n",
       "      <td>MULTIPOLYGON (((-118.60442 33.47855, -118.5987...</td>\n",
       "      <td>27213650</td>\n",
       "      <td>0.035712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>colorado</th>\n",
       "      <td>54028</td>\n",
       "      <td>08</td>\n",
       "      <td>01779779</td>\n",
       "      <td>0400000US08</td>\n",
       "      <td>08</td>\n",
       "      <td>CO</td>\n",
       "      <td>00</td>\n",
       "      <td>268422891711</td>\n",
       "      <td>1181621593</td>\n",
       "      <td>POLYGON ((-109.06025 38.59933, -109.05954 38.7...</td>\n",
       "      <td>4235384</td>\n",
       "      <td>0.012756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count statefp   statens     affgeoid geoid stusps lsad  \\\n",
       "alabama      56989      01  01779775  0400000US01    01     AL   00   \n",
       "arizona      93038      04  01779777  0400000US04    04     AZ   00   \n",
       "arkansas      5089      05  00068085  0400000US05    05     AR   00   \n",
       "california  971856      06  01779778  0400000US06    06     CA   00   \n",
       "colorado     54028      08  01779779  0400000US08    08     CO   00   \n",
       "\n",
       "                   aland       awater  \\\n",
       "alabama     131174048583   4593327154   \n",
       "arizona     294198551143   1027337603   \n",
       "arkansas    134768872727   2962859592   \n",
       "california  403503931312  20463871877   \n",
       "colorado    268422891711   1181621593   \n",
       "\n",
       "                                                     geometry  total_drivers  \\\n",
       "alabama     MULTIPOLYGON (((-88.05338 30.50699, -88.05109 ...        4026151   \n",
       "arizona     POLYGON ((-114.81629 32.50804, -114.81432 32.5...        5369210   \n",
       "arkansas    POLYGON ((-94.61783 36.49941, -94.61765 36.499...        2153929   \n",
       "california  MULTIPOLYGON (((-118.60442 33.47855, -118.5987...       27213650   \n",
       "colorado    POLYGON ((-109.06025 38.59933, -109.05954 38.7...        4235384   \n",
       "\n",
       "            acc_per_cap  \n",
       "alabama        0.014155  \n",
       "arizona        0.017328  \n",
       "arkansas       0.002363  \n",
       "california     0.035712  \n",
       "colorado       0.012756  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "national_group.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "**Convert acc_df to a Geopandas Dataframe**\n",
    "___________\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping rows that I won't be using in the plots\n",
    "acc_df.drop(columns = ['temperature(f)', 'wind_chill(f)', 'humidity(%)', 'pressure(in)', 'visibility(mi)', \n",
    "                       'wind_direction', 'wind_speed(mph)', 'precipitation(in)', 'weather_condition', \n",
    "                       'sunrise_sunset', 'civil_twilight', 'nautical_twilight', 'astronomical_twilight'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converting acc_df to geopandas df\n",
    "# gdp is the geopandas imported as gpd\n",
    "# GeoDataFrame is a function that converts objects to GeoPandas DF's\n",
    "# Since There is not geometry object (column) we need to use .points_from_xy\n",
    "# .points_from_xy() function converts latitude and longitude columns to geometry object. \n",
    "# geometry object will be used to plot in geospatial data. \n",
    "\n",
    "acc_gdf = gpd.GeoDataFrame(\n",
    "    acc_df, geometry = gpd.points_from_xy(acc_df['start_lat'], acc_df['start_lng']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__________________\n",
    "**Splitting Up acc_gdf into smaller portions**\n",
    "__________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the length of each new split dataframe\n",
    "# Splitting 10 times so multiplying length of the dataframe by .10\n",
    "len_new = int(round(len(acc_gdf) * .10, 0))\n",
    "\n",
    "# Creating 10 new dataframes of 10 percent of total samples in each new dataframe. \n",
    "# Now I will use len_new to index the new dataframes\n",
    "acc_gdf1 = acc_gdf.iloc[0:len_new, :]\n",
    "acc_gdf2 = acc_gdf.iloc[len_new:(len_new * 2),  :]\n",
    "acc_gdf3 = acc_gdf.iloc[(len_new * 2):(len_new * 3),  :]\n",
    "acc_gdf4 = acc_gdf.iloc[(len_new * 3): (len_new * 4), :]\n",
    "acc_gdf5 = acc_gdf.iloc[(len_new * 4): (len_new * 5), :]\n",
    "acc_gdf6 = acc_gdf.iloc[(len_new * 5): (len_new * 6), :]\n",
    "acc_gdf7 = acc_gdf.iloc[(len_new * 6): (len_new * 7), :]\n",
    "acc_gdf8 = acc_gdf.iloc[(len_new * 7): (len_new * 8), :]\n",
    "acc_gdf9 = acc_gdf.iloc[(len_new * 8): (len_new * 9), :]\n",
    "acc_gdf10 = acc_gdf.iloc[(len_new * 9): (len_new * 10), :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving all of the split dfs to csv so that I can use keppler on the web.\n",
    "acc_gdf1.to_csv('../data/acc_gdf1.csv') \n",
    "acc_gdf2.to_csv('../data/acc_gdf2.csv')\n",
    "acc_gdf3.to_csv('../data/acc_gdf3.csv') \n",
    "acc_gdf4.to_csv('../data/acc_gdf4.csv') \n",
    "acc_gdf5.to_csv('../data/acc_gdf5.csv') \n",
    "acc_gdf6.to_csv('../data/acc_gdf6.csv') \n",
    "acc_gdf7.to_csv('../data/acc_gdf7.csv') \n",
    "acc_gdf8.to_csv('../data/acc_gdf8.csv') \n",
    "acc_gdf9.to_csv('../data/acc_gdf9.csv') \n",
    "acc_gdf10.to_csv('../data/acc_gdf10.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_________\n",
    "**Plotting**\n",
    "__________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_____________________________\n",
    "# Kepler.gl Plot\n",
    "Created a basic national map with accident count, licensed drivers and percentage of accidents per capita (derived by dividing accident count by licensed drivers per state)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://docs.kepler.gl/docs/keplergl-jupyter\n"
     ]
    }
   ],
   "source": [
    "map_acc = KeplerGl(height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding split dataframes to Keppler using add_data() function.\n",
    "# I had to split the dataframes (see above) into managable data sizes. Luckily keppler allows you to add as many times as necessary. \n",
    "\n",
    "map_acc.add_data(data = acc_gdf1, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf2, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf3, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf4, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf5, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf6, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf7, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf8, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf9, name = 'Accidents')\n",
    "map_acc.add_data(data = acc_gdf10, name = 'Accidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# display function calls added data and as you add each new layer (above) you will see the data update into this cell.\n",
    "# The interactive map displays here.\n",
    "display(map_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Keppler plot of just the State Counts and Per Capita Counts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_gdf = gpd.GeoDataFrame(national_group)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ng_gdf = ng_gdf.loc[:, ['count', 'geometry', 'total_drivers', 'acc_per_cap']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate KeplerGl\n",
    "map_1 = KeplerGl(height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to KeplerGl instance\n",
    "map_1.add_data(data = ng_gdf, name = 'NationalAccidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# display(map_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other GeoSpatial Plots\n",
    "https://geopandas.org/gallery/create_geopandas_from_pandas.html\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = geopandas.GeoDataFrame(\n",
    "    df, geometry=geopandas.points_from_xy(df.Longitude, df.Latitude))\n",
    "\n",
    "world = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "\n",
    "# We restrict to South America.\n",
    "ax = world[world.continent == 'South America'].plot(\n",
    "    color='white', edgecolor='black')\n",
    "\n",
    "# We can now plot our ``GeoDataFrame``.\n",
    "gdf.plot(ax=ax, color='red')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________\n",
    "## Bar Plots of Accidents Per State, County and City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "**Accidents Per State**\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a df with accident count and total licensed drivers per state. \n",
    "acc_per_state = pd.concat([state_count, license_df], axis = 1)\n",
    "acc_per_state.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating a accident per capita column\n",
    "acc_per_state['acc_per_cap'] = acc_per_state['count'] / acc_per_state['total_drivers']\n",
    "acc_per_state.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resetting index to numeric index\n",
    "acc_per_state = acc_per_state.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "**Plot of Accidents by State**\n",
    "______________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df of acc_per_state sorted by count\n",
    "acc_count = acc_per_state.sort_values('count', ascending = False)\n",
    "\n",
    "# creating variables to house plotting coordinates\n",
    "x = list(acc_count['count'])\n",
    "bars = list(acc_count['state'])\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize = (12,9))\n",
    "plt.barh(y_pos, x, color = 'red')\n",
    "plt.yticks(y_pos, bars, color = 'black')\n",
    "plt.xticks(color = 'black')\n",
    "plt.xlabel('Accident Count', color = 'black')\n",
    "plt.ylabel('State', color = 'black')\n",
    "plt.title('Accidents by State', color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Plot of Accidents by State**\n",
    "__________________\n",
    "\n",
    "* Not surprisingly California, Texas and Florida rank highest in number of accidents per state. Afterall, they are the three largest states. **What was surprising, however, is North and South Carolina in the top five.** What factors contribute to such a high number of accidents in these two states?\n",
    "\n",
    "* Looking at the bottom tier of states appears to confirm the relationship between population and number of accidents. Again, this is not surprising. \n",
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______________\n",
    "**Plot of Largest Per Capita Accidents Rates By State**\n",
    "_______________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# creating new df of acc_per_state sorted by count\n",
    "acc_pcapita = acc_per_state.sort_values('acc_per_cap', ascending = False)\n",
    "\n",
    "# creating variables to house plotting coordinates\n",
    "x = list(acc_pcapita['acc_per_cap'])\n",
    "bars = list(acc_pcapita['state'])\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# plotting\n",
    "plt.figure(figsize = (12,9))\n",
    "plt.barh(y_pos, x, color = 'red')\n",
    "plt.yticks(y_pos, bars, color = 'black')\n",
    "plt.xticks(color = 'black')\n",
    "plt.xlabel('Per Capita Accident Rate', color = 'black')\n",
    "plt.ylabel('State', color = 'black')\n",
    "plt.title('Per Capita Accident Rate by State', color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Largest Per Capita Accidents By State Plot**\n",
    "__________________\n",
    "* Based on the chart of total number of accidents in each state we would expect to see South Carolina and North Carolina in the top 10. Interestingly, California remains in top 3 on a per-capita basis. In light of this it appears that anecdotal evidence is confirmed by the data to be a relatively challenging state to drive in.\n",
    "\n",
    "* North Dakot and South Dakota remain at the bottom of the charts when accident totals are adjusted on a per-capita basis. **This highlights a potential relationship between population density and accidents.** \n",
    "\n",
    "* Possible exceptions to population density, when considering this on a state level, is Oregon and Utah which are both in top-ten on a per-capita basis and have a diverse population of rural and urban populations. **It may be worth looking into these states further to identify per-capita proportions of accident totals on a rural county or city level.**\n",
    "_____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________________\n",
    "**Plot of Top 25 Accidents Per County**\n",
    "_______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Creating a new df with accidents counts per county\n",
    "acc_per_county = acc_df.groupby('county')[['severity']].count()\n",
    "# Renaming severity column to count\n",
    "acc_per_county.rename(columns = {'severity': 'count'}, inplace = True)\n",
    "acc_per_county.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df of acc_per_county sorted by count\n",
    "acc_county_count_25 = acc_county_count.nlargest(25, 'count')\n",
    "\n",
    "# creating variables to house plot coordinates\n",
    "x = list(acc_county_count_25['count'])\n",
    "bars = list(acc_county_count_25.index)\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize = (12,9))\n",
    "plt.barh(y_pos, x, color = 'red')\n",
    "plt.yticks(y_pos, bars, color = 'black')\n",
    "plt.xticks(color = 'black')\n",
    "plt.xlabel('Accident Count', color = 'black')\n",
    "plt.ylabel('County', color = 'black')\n",
    "plt.title('Per County Accident Count', color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Plot of Accident Count Per County**\n",
    "* Los Angeles County, is a driver-centric metropolis tops this list almost tripling the accident count of Harris County, Texas. Harris County, the third largest county in the United States is the home of Houston and is a sprawling county growing at a 15% clip annually. These values are to be expected at the top of the chart. \n",
    "\n",
    "* I would like to do more analysis on population density and accident rates. If you look at the top counties for accident count Many of them are not in the top 50 of population density. So it almost seems as if at some point population density increases then motor vehicle accidents then decrease. This is likely due to the fact that less people drive and more take mass transit. For instance, Los Angeles County is one of the largest counties by population in the United States but doesn't even break the top 50 counties based on population density. Neither does number two Harris County and number three Orange County ranks 32nd. In fact, Cook County (ranked 19th in population density) is the only county in the list of top 25 of total accident counts that cracks the top 20 via population density. \n",
    "* This lack of extreme dense population in the highest accident count counties suggests that larger-by-land-mass, sprawling cities that are more dependent on personal motor vehicles for travel are certainly more risky than densely populated metropolis' that have a good mix of public and private transportation options. However, further research is needed here. \n",
    "* This article published on PBS illustrates some of the reason higher-density areas have less crash rates. In a four-year long study at the University of Pennsylvania co-author of the study, Erick Guerra explains that \"Fewer roads and slower traffic speeds in Philly explain some of the difference in crash rates. The region’s densest census tracts house 28% of the Delaware Valley’s population, but just 6% of all roadways and far fewer high-speed boulevards or highways. Across the five-county region, roads with average speeds of 45 miles-per-hour witnessed 10 times more deaths on average than roads with 25 miles-per-hour speed limits, the study found.\"\n",
    "* Another study found that severity of crashes increases as areas become more rural. This is partly due to people wearing their seatbelts less in rural areas, higher speeds in which people travel in rural areas, increased per capital impaired driving rates and less proximity to trauma centers that can triage severe accidents. There was also some mention of people in rural areas tending to have lower wages and thus driving older cars with outdated or less existent safety features. \n",
    "\n",
    "\n",
    "**Sources**\n",
    "\n",
    "List of most populous counties in the United States\n",
    "* https://en.wikipedia.org/wiki/List_of_the_most_populous_counties_in_the_United_States\n",
    "\n",
    "List of most densely populated counties in the United States. \n",
    "\n",
    "* https://en.wikipedia.org/wiki/County_statistics_of_the_United_States#Most_densely_populated\n",
    "\n",
    "City driving often safer than the burbs\n",
    "* https://whyy.org/articles/study-city-driving-often-safer-than-the-burbs/\n",
    "\n",
    "Car crash death rates highest in remotest rural areas\n",
    "* https://www.reuters.com/article/us-health-rural-autos-crash/car-crash-death-rates-highest-in-remotest-rural-areas-idUSKBN1CA2EW\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "**Plot of Top 25 Accidents Per City**\n",
    "____________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_per_city = acc_df.groupby('city')[['severity']].count()\n",
    "acc_per_city.rename(columns = {'severity': 'count'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating new df of acc_per_city sorted by count\n",
    "acc_city_count_25 = acc_per_city.nlargest(25, 'count')\n",
    "\n",
    "# creating variables to house plot coordinates\n",
    "x = list(acc_city_count_25['count'])\n",
    "bars = list(acc_city_count_25.index)\n",
    "y_pos = np.arange(len(bars))\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize = (12,9))\n",
    "plt.barh(y_pos, x, color = 'red')\n",
    "plt.yticks(y_pos, bars, color = 'black')\n",
    "plt.xticks(color = 'black')\n",
    "plt.xlabel('Accident Count', color = 'black')\n",
    "plt.ylabel('City', color = 'black')\n",
    "plt.title('Per City Accident Count', color = 'black')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________\n",
    "### Plot of Crossing and Severity\n",
    "A crossing refers to any crossing across roads for pedestrians, cyclists, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_crossing = acc_df['crossing'].sum()\n",
    "perc_crossing = round((total_crossing / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_crossing} reported crossings in this dataset comprising {perc_crossing}% of the samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['crossing'] = acc_df['crossing'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=2, palette= ['orange', 'red'])\n",
    "sns.countplot(data = acc_df, x = 'severity', hue = 'crossing')\n",
    "plt.title('Crossing and Severity')\n",
    "plt.legend(['No Crossing', 'Crossing'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Severity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Crossing and Severity Plot**\n",
    "* The vast majority of all accidents that happened at a crossing had a severity of level 2. \n",
    "___________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "### Plot of Junction and Severity\n",
    "A junction refers to any highway ramp, exit or entrance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_junction = acc_df['junction'].sum()\n",
    "perc_junction = round((total_junction / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_junction} reported junctions in this dataset comprising {perc_junction}% of the samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['junction'] = acc_df['junction'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=2, palette= ['orange', 'red'])\n",
    "sns.countplot(data = acc_df, x = 'severity', hue = 'junction')\n",
    "plt.title('Junction and Severity')\n",
    "plt.legend(['No Junction', 'Junction'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Severity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Junction and Severity**\n",
    "* Of all the categorical features plotted to this point junction comprises the largest percentage of values accounting for around 8% of the dataset. It appears that the majority of accidents that happen near a highway ramp, exit or entrance have a severity of level 2 and many have a severity of level 3. Very few, if any have level 1 or 4. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "______\n",
    "### Plot of Station and Severity\n",
    "Refers to a public transportation station (bus, metro, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_station = acc_df['station'].sum()\n",
    "perc_station = round((total_station / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_station} reported stations in this dataset comprising {perc_station}% of the samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['station'] = acc_df['station'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=2, palette= ['orange', 'red'])\n",
    "sns.countplot(data = acc_df, x = 'severity', hue = 'station')\n",
    "plt.title('Station and Severity')\n",
    "plt.legend(['No Station', 'Station'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Severity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Plot of Station and Severity**\n",
    "* It appears that mostly all of the accidents that happen near a public transportation station have a severity level of 2. \n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "### Plot of Stop and Severity\n",
    "Refers to a stop sign at scene of accident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_stop = acc_df['stop'].sum()\n",
    "perc_stop = round((total_stop / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_stop} reported stop signs in this dataset comprising {perc_stop}% of the samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['stop'] = acc_df['stop'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=2, palette= ['orange', 'red'])\n",
    "sns.countplot(data = acc_df, x = 'severity', hue = 'stop')\n",
    "plt.title('Station and Stop Sign')\n",
    "plt.legend(['No Stop Sign', 'Stop Sign'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Severity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Stop Sign and Severity**\n",
    "* It appears that nearly all accidents that happen at a stop sign have a severity of level 2. I feel the amount of incidents reported at stop signs seems low. This may have to do with the integrity of the recording process but it may also be right. No way to know for sure at this point. \n",
    "________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "### Plot of Traffic Signal and Severity\n",
    "Refers to traffic signal on intersections present at accident site. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_signal = acc_df['traffic_signal'].sum()\n",
    "perc_signal = round((total_signal / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_signal} reported traffic signals in this dataset comprising {perc_signal}% of the samples.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_df['signal'] = acc_df['signal'].map({True: 1, False: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.set(font_scale=2, palette= ['orange', 'red'])\n",
    "sns.countplot(data = acc_df, x = 'severity', hue = 'traffic_signal')\n",
    "plt.title('Station and Traffic Signal')\n",
    "plt.legend(['No Traffic Signal', 'Traffic Signal'])\n",
    "plt.ylabel('Frequency')\n",
    "plt.xlabel('Severity')\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis of Plot of Traffic Singal and Severity**\n",
    "\n",
    "Traffic signal has been the largest of the categorical feature variables analayzed against severity to this point. The presence of a traffic signal may reduce the severity of an accident slightly as you can see the proportion of level 2 and level 3 accidents that do not have a traffic signal seems to be smaller than the proportion of level 2 over level 3 accidents that occur when a traffic signal is present. This signifies a benefit to having traffic signals present at an intersection. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________\n",
    "### Categorical Features that do not offer enough data to analyze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Give-Way Feature**\n",
    "Give-way refers to a sign on road which shows priority of passing.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_giveway = acc_df['give_way'].sum()\n",
    "perc_giveway = round((total_giveway / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_giveway} reported give-ways in this dataset comprising {perc_giveway}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Amenity Feature**\n",
    "In the context of this data an ammenity refers to a particular place such as restaurant, library, college, bar, etc. where an accident occurred.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_amenity = acc_df['amenity'].sum()\n",
    "perc_amenity = round((total_amenity / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_amenity} reported amenties in this dataset comprising {perc_ammenity}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bump Feature**Refers to speed bump or hump to reduce the speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_bump = acc_df['bump'].sum()\n",
    "perc_bump = round((total_bump / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_bump} reported bumps in this dataset comprising {perc_bump}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**No-exit Feature**\n",
    "No-exit indicates there is no possibility to travel further by any transport mode along a formal path or route. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_noexit = acc_df['no_exit'].sum()\n",
    "perc_noexit = round((total_noexit / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_noexit} reported no-exits in this dataset comprising {perc_noexit}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Railway Feature**Indicates the presence of railways near accident. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rail = acc_df['railway'].sum()\n",
    "perc_rail = round((total_rail / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_rail} reported railways in this dataset comprising {perc_rail}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Give-Way Feature**\n",
    "Give-way is a sign on road which shows priority of passing. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_giveway = acc_df['give_way'].sum()\n",
    "perc_giveway = round((total_giveway / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_giveway} reported give-ways in this dataset comprising {perc_giveway}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Roundabout Feature**\n",
    "Refers to a circular road junction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_rbout = acc_df['roundabout'].sum()\n",
    "perc_rbout = round((total_rbout / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_rbout} reported roundabout in this dataset comprising {perc_rbout}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Traffic Calming Feature** Refers to any means for slowing down traffic speed. This is interesting feature since bump is also a feature and bump would fall under this category. Maybe it would efficeint to combine these two features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_calm = acc_df['traffic_calming'].sum()\n",
    "perc_calm = round((total_calm / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_calm} reported traffic calming mechanisms in this dataset comprising {perc_calm}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Turning Loop Feature**\n",
    "Indicates a widened area of a highway with a non-traverable island for turning around. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_loop = acc_df['turning_loop'].sum()\n",
    "perc_loop = round((total_loop / len(acc_df) * 100), 2)\n",
    "print(f\"There are {total_loop} reported turning loops in this dataset comprising {perc_loop}% of the samples.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "____________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start_Time and Severity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting acc_df to geopandas df. \n",
    "# This also converts latitude and longitude columns to geomtry columns (these are shapely objects)\n",
    "# https://gis.stackexchange.com/questions/174159/converting-pandas-dataframe-to-geodataframe/258376#258376\n",
    "gdf = gpd.GeoDataFrame(acc_df, \n",
    "                             geometry=gpd.points_from_xy(x=acc_df['start_lng'], y=acc_df['start_lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "map_2 = KeplerGl(height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add data to KeplerGl instance\n",
    "map_2.add_data(data = gdf, name = 'Accidents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(map_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "location_df = acc_df.loc[:, ['start_lat', 'start_lng']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_gdf = gpd.GeoDataFrame(location_df, \n",
    "                             geometry=gpd.points_from_xy(x=acc_df['start_lng'], y=acc_df['start_lat']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_3 = KeplerGl(height = 400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map_3.add_data(data = gdf, name = \"Accident Location\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(map_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ng_gdf.plot(figsize = (20,20));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "national_shape.plot(, column='id', cmap='Oranges', figsize=(40, 80))\n",
    "acc_df.plot(figsize = (40, 80))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acc.plot(kind = \"scatter\", x=\"Start_Lng\",y=\"Start_Lat\",alpha = 0.009)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_acc.plot(kind = \"scatter\", x=\"Start_Lng\",y=\"Start_Lat\",alpha = 0.009,c=\"Severity\", \n",
    "            cmap=plt.get_cmap(\"jet\"), colorbar = False, figsize=(15,7))\n",
    "plt.figure(figsize=(20,12))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
